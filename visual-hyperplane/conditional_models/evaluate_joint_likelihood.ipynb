{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from models import VAE, loss_function\n",
    "from problems import get_problem\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "p = get_problem('sum_25', 'int', train_ratio=1.)\n",
    "\n",
    "def get_digit(digit, train):\n",
    "    test_digits = []\n",
    "    for data, label in datasets.MNIST('../data', train=train, download=True, transform=transforms.ToTensor()):\n",
    "        if digit == -1 or label.item() == digit:\n",
    "            test_digits.append((data, label))\n",
    "    return test_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some problems\n",
    "uniform = get_problem('uniform', 'int', train_ratio=1.)\n",
    "sum_25 = get_problem('sum_25', 'int', train_ratio=1.)\n",
    "increasing = get_problem('increasing', 'int', train_ratio=1.)\n",
    "symmetric = get_problem('symmetric', 'int', train_ratio=1.)\n",
    "even = get_problem('even', 'int', train_ratio=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all Gaussians\n",
    "gaussian_models = torch.load('gaussian_models.pkl')\n",
    "gaussian_models['mean']\n",
    "\n",
    "# Sample from diagonal gaussian\n",
    "def sample_diag(digit, means, var):\n",
    "    z = torch.randn(len(var[digit]))\n",
    "    x = means[digit] + torch.sqrt(var[digit]) * z\n",
    "    print (torch.sqrt(var[digit])).size()\n",
    "    return x\n",
    "\n",
    "# Sample from full gaussian\n",
    "def sample_full(digit, means, cholesky):\n",
    "    z = torch.randn(len(cholesky[digit]))\n",
    "    x = means[digit] + cholesky[digit].matmul(z)\n",
    "    return x\n",
    "\n",
    "sample = sample_full(8, gaussian_models['mean'], gaussian_models['cholesky'])\n",
    "\n",
    "import scipy.stats\n",
    "gaussians = {}\n",
    "REGULARIZATION = 1e-3\n",
    "for i in xrange(10):\n",
    "    gaussian = scipy.stats.multivariate_normal(mean=gaussian_models['mean'][i],\n",
    "                                   cov=np.identity(784)*REGULARIZATION + gaussian_models['fullvar'][i])\n",
    "    gaussians[i] = gaussian\n",
    "    \n",
    "sample = sample_full(2, gaussian_models['mean'], gaussian_models['cholesky'])\n",
    "gaussians[3].logpdf(sample)\n",
    "\n",
    "# Build visual models (from Full Gaussians)\n",
    "def create_visual_model(digit_idx, gaussian_models, REGULARIZATION=1e-3):\n",
    "    gaussian = scipy.stats.multivariate_normal(mean=gaussian_models['mean'][digit_idx],\n",
    "                                       cov=np.identity(784)*REGULARIZATION + gaussian_models['fullvar'][digit_idx])\n",
    "    def visual_model(digit_image):\n",
    "        x = digit_image.view(-1)\n",
    "        nll = - gaussian.logpdf(x)\n",
    "        return nll\n",
    "    return visual_model\n",
    "visual_models = [create_visual_model(i, gaussian_models) for i in xrange(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1098975d0>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample.numpy().reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all VAES\n",
    "vaes = {}\n",
    "#EPOCH = 80\n",
    "EPOCH = 70\n",
    "for i in xrange(10):\n",
    "    vae = VAE()\n",
    "    state_dict = torch.load('epoch_{}/digit_{}_epoch_{}.pth'.format(EPOCH, i, EPOCH))\n",
    "    vae.load_state_dict(state_dict)\n",
    "    vaes[i] = vae\n",
    "    \n",
    "# Build visual models (from VAEs)\n",
    "def create_visual_model(digit_idx, vaes):\n",
    "    def visual_model(digit_image):\n",
    "        x = digit_image.view((1, 1, 28, 28))\n",
    "        reconstruction, mu, logvar = vaes[digit_idx](x)\n",
    "        nll = loss_function(reconstruction, x, mu, logvar)\n",
    "        return nll\n",
    "    return visual_model\n",
    "visual_models = [create_visual_model(i, vaes) for i in xrange(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading digit 0\n",
      "Loading digit 1\n",
      "Loading digit 2\n",
      "Loading digit 3\n",
      "Loading digit 4\n",
      "Loading digit 5\n",
      "Loading digit 6\n",
      "Loading digit 7\n",
      "Loading digit 8\n",
      "Loading digit 9\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Load all MNISTs\n",
    "batch_size = 1\n",
    "\n",
    "# Load all MNIST digits\n",
    "test_digits = {}\n",
    "test_loaders = {}\n",
    "for i in xrange(10):\n",
    "    print 'Loading digit', i\n",
    "    test_digit = get_digit(i, train=False)\n",
    "    test_digits[i] = test_digit\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_digit, batch_size=batch_size, shuffle=True)\n",
    "    test_loaders[i] = test_loader\n",
    "    \n",
    "# Build visual samplers (from test set)\n",
    "def create_visual_sampler(i, test_loaders):\n",
    "    def visual_sampler():\n",
    "        return iter(test_loaders[int(i)]).next()[0][0,0]\n",
    "    return visual_sampler\n",
    "visual_samplers = [create_visual_sampler(i, test_loaders) for i in xrange(10)]\n",
    "\n",
    "print visual_samplers[8]().size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Combination to Image Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size torch.Size([5, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combination to Visual\n",
    "def to_visual(combination, visual_samplers):\n",
    "    '''\n",
    "    Sample a visual representation for a symbolic combination\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    combination: np.ndarray (part~5) combination to encode\n",
    "    visual_samplers: dict of 10 callable objects which return a random corresponding (28, 28) digit\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    visual_combination: torch.Tensor (part~5, height~28, width~28)\n",
    "    '''\n",
    "    x = []\n",
    "    for c in combination:\n",
    "        sample = visual_samplers[c]()\n",
    "        x.append(sample[None, :, :])\n",
    "    visual_combination = torch.cat(x)\n",
    "    return visual_combination\n",
    "\n",
    "# Test: combination to visual_combination    \n",
    "visual_combination = to_visual([3, 1, 4, 1, 5], visual_samplers)\n",
    "\n",
    "print 'Size', visual_combination.size()\n",
    "for i in xrange(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(visual_combination[i].numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood of Sum-25 with Joint generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1143ca2d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precompute conditional visual likelihoods\n",
    "def get_per_digit_likelihood(visual_combination, visual_models):  # return -log likelihoods\n",
    "    '''\n",
    "    Compute NLL given by each visual model (e.g. VAE) to each visual digit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    visual_combination: torch.Tensor (part~5, height~28, width~28)\n",
    "    visual_models: dictionary of objects which can be called on x and return a nll\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    visual_likelihoods: np.ndarray (part~5, digit~10)\n",
    "    ''' \n",
    "    visual_likelihoods = np.zeros((5, 10))\n",
    "    for part in xrange(5):\n",
    "        for model_idx in xrange(10):\n",
    "            digit_image = visual_combination[part]\n",
    "            l = visual_models[model_idx](digit_image)\n",
    "            visual_likelihoods[part, model_idx] = l  # since it's -log likelihood\n",
    "    return visual_likelihoods\n",
    "\n",
    "# Test: get conditional nll for each digit of visual combination\n",
    "visual_likelihoods = get_per_digit_likelihood(visual_combination, visual_models)\n",
    "plt.imshow(visual_likelihoods, 'gray')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest combination match [3 7 4 6 5]\n",
      "Likelihood 482.86708156528493\n"
     ]
    }
   ],
   "source": [
    "# Sum over all combinations in symbolic model\n",
    "conditional_likelihoods = []\n",
    "\n",
    "def log_sum_exp(v):\n",
    "    v = np.asarray(v)\n",
    "    v_max = v.max()\n",
    "    return v_max + np.log(np.sum(np.exp(v - v_max)))\n",
    "\n",
    "\n",
    "def get_one_sample_likelihood(visual_likelihoods, model_combinations):\n",
    "    '''\n",
    "    Return likelihood given by a joint model for one visual sample.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    visual_likelihoods: np.ndarray (part~5, digit~10) of per_digit likelihoods\n",
    "    model_combinations: np.ndarray (combination~1000, part~5) \n",
    "        symbolic model is uniform distribution on those combinations.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    likelihood: nll for that given sample: -log { 1/|C| sum_{z\\in C} p(z) \\prod_i p(x_i | z_i) }\n",
    "    conditional_likelihoods: -\\sum_i \\log p(x_i | z_i)\n",
    "    closest_combination: return combination z in model_combinations with highest likelihood\n",
    "    '''\n",
    "    conditional_likelihoods = []\n",
    "    for combination in model_combinations:  # iterate over possible z\n",
    "        tmp = 0.\n",
    "        for part, c in enumerate(combination):\n",
    "            p_xPart_given_zPart = visual_likelihoods[part, c]\n",
    "            tmp += p_xPart_given_zPart\n",
    "        conditional_likelihoods.append(tmp)\n",
    "    likelihood = np.log(len(model_combinations)) - log_sum_exp(-np.asarray(conditional_likelihoods))  # get NLL\n",
    "    # for debugging return closest combination\n",
    "    best_x_z = np.argmin(conditional_likelihoods)  # smallest log likelihood\n",
    "    closest_combination = model_combinations[best_x_z]\n",
    "    return likelihood, conditional_likelihoods, closest_combination\n",
    "    \n",
    "    \n",
    "# Test: get liklelihood for sample giving visual_likelihood\n",
    "likelihood, conditional_likelihoods, closest_combination = get_one_sample_likelihood(\n",
    "    visual_likelihoods, sum_25.train_positive)\n",
    "\n",
    "# Note that the largest conditional likelihood should correspond classifying the combination\n",
    "# if combination verifies constraint\n",
    "print 'Closest combination match', closest_combination\n",
    "print 'Likelihood', likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat this over all training set combinations X model combinations\n",
    "[Main Function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination # 0\n",
      "Combination [9 0 2 8 6]\n",
      "closest [9 0 2 8 6]\n",
      "Likelihood 541.0409114048445\n",
      "NLL in [541.0; 541.0]\n",
      "Combination # 50\n",
      "Combination [4 9 1 3 8]\n",
      "closest [4 9 1 3 8]\n",
      "Likelihood 429.1041743442976\n",
      "NLL in [476.4; 490.6]\n",
      "Combination # 100\n",
      "Combination [3 7 8 1 6]\n",
      "closest [3 7 8 1 6]\n",
      "Likelihood 414.40949508404367\n",
      "NLL in [484.2; 494.3]\n",
      "Combination # 150\n",
      "Combination [0 8 9 2 6]\n",
      "closest [0 8 9 2 6]\n",
      "Likelihood 485.4522502109968\n",
      "NLL in [484.7; 493.1]\n",
      "NLL in [484.3; 491.7]\n"
     ]
    }
   ],
   "source": [
    "def get_likelihood(target_combinations, model_combinations,\n",
    "                    visual_samplers, visual_models, max_iterations=200):\n",
    "    '''\n",
    "    Return estimated likelihood for \n",
    "    '''\n",
    "    all_likelihoods = []\n",
    "    for i, combination in enumerate(target_combinations):  # true distribution to reach\n",
    "        \n",
    "        if i >= max_iterations:\n",
    "            break\n",
    "        \n",
    "        # Transform symbolic combination to visual\n",
    "        visual_combination = to_visual(combination, visual_samplers)\n",
    "        \n",
    "        # Compute likelihood of each part(digit) with each visual conditional model \n",
    "        visual_likelihoods = get_per_digit_likelihood(visual_combination, visual_models)  \n",
    "        \n",
    "        # Compute likelihood of that visual sample\n",
    "        likelihood, conditional_likelihoods, closest_combination = get_one_sample_likelihood(\n",
    "            visual_likelihoods, model_combinations)  # model distribution\n",
    "\n",
    "        # Logging\n",
    "        all_likelihoods.append(likelihood)\n",
    "        average_nll = np.mean(all_likelihoods)\n",
    "        std = np.std(all_likelihoods) / np.sqrt(len(all_likelihoods))\n",
    "        if i % 50 == 0:\n",
    "            print 'Combination #', i\n",
    "            print 'Combination', combination\n",
    "            print 'closest', closest_combination\n",
    "            print 'Likelihood', likelihood\n",
    "            print 'NLL in [{:.1f}; {:.1f}]'.format(average_nll-std, average_nll+std)  \n",
    "            \n",
    "    return average_nll, std\n",
    "\n",
    "target_combinations = sum_25.train_positive\n",
    "model_combinations = sum_25.train_positive\n",
    "average_nll, std = get_likelihood(target_combinations, model_combinations,\n",
    "                    visual_samplers, visual_models, max_iterations=200)\n",
    "\n",
    "print 'NLL in [{:.1f}; {:.1f}]'.format(average_nll-std, average_nll+std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination # 0\n",
      "Combination [9 0 2 8 6]\n",
      "closest [9 0 2 8 6]\n",
      "Likelihood 591.522726748477\n",
      "NLL in [591.5; 591.5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b2c51fb6d9ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_combinations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m average_nll, std = get_likelihood(target_combinations, model_combinations,\n\u001b[0;32m----> 4\u001b[0;31m                     visual_samplers, visual_models, max_iterations=max_iterations)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0d622884892c>\u001b[0m in \u001b[0;36mget_likelihood\u001b[0;34m(target_combinations, model_combinations, visual_samplers, visual_models, max_iterations)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Compute likelihood of that visual sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         likelihood, conditional_likelihoods, closest_combination = get_one_sample_likelihood(\n\u001b[0;32m---> 20\u001b[0;31m             visual_likelihoods, model_combinations)  # model distribution\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f7fd957c4eda>\u001b[0m in \u001b[0;36mget_one_sample_likelihood\u001b[0;34m(visual_likelihoods, model_combinations)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_combinations\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# iterate over possible z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mp_xPart_given_zPart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisual_likelihoods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_xPart_given_zPart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_combinations = sum_25.train_positive\n",
    "model_combinations = uniform.train_positive\n",
    "average_nll, std = get_likelihood(target_combinations, model_combinations,\n",
    "                    visual_samplers, visual_models, max_iterations=max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination # 0\n",
      "Combination [9 0 2 8 6]\n",
      "closest [9 0 2 3 6]\n",
      "Likelihood 583.6769393552838\n",
      "NLL in [583.7; 583.7]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45879d81903b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_combinations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m average_nll, std = get_likelihood(target_combinations, model_combinations,\n\u001b[0;32m----> 4\u001b[0;31m                     visual_samplers, visual_models, max_iterations=200)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0d622884892c>\u001b[0m in \u001b[0;36mget_likelihood\u001b[0;34m(target_combinations, model_combinations, visual_samplers, visual_models, max_iterations)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Compute likelihood of that visual sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         likelihood, conditional_likelihoods, closest_combination = get_one_sample_likelihood(\n\u001b[0;32m---> 20\u001b[0;31m             visual_likelihoods, model_combinations)  # model distribution\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f7fd957c4eda>\u001b[0m in \u001b[0;36mget_one_sample_likelihood\u001b[0;34m(visual_likelihoods, model_combinations)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_combinations\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# iterate over possible z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mp_xPart_given_zPart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisual_likelihoods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp_xPart_given_zPart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target_combinations = sum_25.train_positive\n",
    "model_combinations = uniform.train_positive\n",
    "average_nll, std = get_likelihood(target_combinations, model_combinations,\n",
    "                    visual_samplers, visual_models, max_iterations=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sum_25 with UNIFORM-model\n",
      "Combination # 0\n",
      "Combination [4 8 8 3 2]\n",
      "closest [4 8 8 3 2]\n",
      "Likelihood 511.430874892179\n",
      "NLL in [511.4; 511.4]\n",
      "Combination # 50\n",
      "Combination [9 4 2 2 8]\n",
      "closest [9 4 2 2 8]\n",
      "Likelihood 494.2050237034475\n",
      "NLL in [492.0; 506.6]\n",
      "Combination # 100\n",
      "Combination [3 7 5 3 7]\n",
      "closest [3 7 8 3 7]\n",
      "Likelihood 504.66052527384505\n",
      "NLL in [486.6; 497.4]\n",
      "Combination # 150\n",
      "Combination [8 4 6 6 1]\n",
      "closest [8 4 6 6 1]\n",
      "Likelihood 461.3395856149088\n",
      "NLL in [487.5; 496.6]\n",
      "Combination # 200\n",
      "Combination [6 2 9 1 7]\n",
      "closest [6 2 9 1 7]\n",
      "Likelihood 459.26342382566185\n",
      "NLL in [490.3; 498.0]\n",
      "Combination # 250\n",
      "Combination [6 6 5 6 2]\n",
      "closest [6 6 5 6 3]\n",
      "Likelihood 496.0078641734652\n",
      "NLL in [491.5; 498.5]\n"
     ]
    }
   ],
   "source": [
    "all_problems = ['sum_25', 'increasing', 'symmetric', 'even']\n",
    "uniform = get_problem('uniform', 'int', train_ratio=1.)\n",
    "max_iterations = 2000\n",
    "\n",
    "# (key_1, key_2) key_1 is target, key_2 is model\n",
    "average_nlls = {}\n",
    "stds = {}\n",
    "\n",
    "for p in all_problems:\n",
    "    target_problem = get_problem(p, 'int', train_ratio=1.)\n",
    "    # Compute target vs. uniform model\n",
    "    print '\\n{} with {}-model'.format(p, 'UNIFORM')\n",
    "    average_nll, std = get_likelihood(target_problem.train_positive, uniform.train_positive,\n",
    "                    visual_samplers, visual_models, max_iterations=max_iterations)\n",
    "    average_nlls[(p, 'uniform')] = average_nll\n",
    "    stds[(p, 'uniform')] = std\n",
    "    # Compute target vs. target model\n",
    "    print '\\n{} with {}-model'.format(p, p)\n",
    "    average_nll, std = get_likelihood(target_problem.train_positive, target_problem.train_positive,\n",
    "                    visual_samplers, visual_models, max_iterations=max_iterations)\n",
    "    average_nlls[(p, p)] = average_nll\n",
    "    stds[(p, p)] = std    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('even', 'even'): 572.1490852561102,\n",
       " ('even', 'uniform'): 573.407292973076,\n",
       " ('increasing', 'increasing'): 568.3391140220898,\n",
       " ('increasing', 'uniform'): 569.5316872201712,\n",
       " ('sum_25', 'sum_25'): 575.407282397065,\n",
       " ('sum_25', 'uniform'): 572.3051066949844,\n",
       " ('symmetric', 'symmetric'): 563.8768181342056,\n",
       " ('symmetric', 'uniform'): 571.9257354390335}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_nlls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('even', 'even'): 1.2171978858548096,\n",
       " ('even', 'uniform'): 1.2668743925587675,\n",
       " ('increasing', 'increasing'): 1.3597330309634366,\n",
       " ('increasing', 'uniform'): 1.4075802609068047,\n",
       " ('sum_25', 'sum_25'): 1.1829772798830123,\n",
       " ('sum_25', 'uniform'): 1.1818917495160075,\n",
       " ('symmetric', 'symmetric'): 2.1689768139683823,\n",
       " ('symmetric', 'uniform'): 2.076468640541826}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('even', 'even'): 572.1 +/- 1.5\n",
      "('even', 'uniform'): 573.4 +/- 1.6\n",
      "('increasing', 'increasing'): 568.3 +/- 1.7\n",
      "('increasing', 'uniform'): 569.5 +/- 1.7\n",
      "('sum_25', 'sum_25'): 575.4 +/- 1.5\n",
      "('sum_25', 'uniform'): 572.3 +/- 1.4\n",
      "('symmetric', 'symmetric'): 563.9 +/- 2.6\n",
      "('symmetric', 'uniform'): 571.9 +/- 2.6\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "for key in average_nlls:\n",
    "    lines.append('{}: {:.1f} +/- {:.1f}'.format(key, average_nlls[key], stds[key]))\n",
    "lines = sorted(lines)\n",
    "print '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
