{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from models import VAE, loss_function\n",
    "from problems import get_problem\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "p = get_problem('sum_25', 'int', train_ratio=1.)\n",
    "\n",
    "def get_digit(digit, train):\n",
    "    test_digits = []\n",
    "    for data, label in datasets.MNIST('../data', train=train, download=True, transform=transforms.ToTensor()):\n",
    "        if digit == -1 or label.item() == digit:\n",
    "            test_digits.append((data, label))\n",
    "    return test_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all VAES\n",
    "vaes = {}\n",
    "for i in xrange(10):\n",
    "    vae = VAE()\n",
    "    state_dict = torch.load('digit_{}_epoch_80.pth'.format(i))\n",
    "    vae.load_state_dict(state_dict)\n",
    "    vaes[i] = vae\n",
    "    \n",
    "# Build visual models (from VAEs)\n",
    "def create_visual_model(digit_idx, vaes):\n",
    "    def visual_model(digit_image):\n",
    "        x = digit_image.view((1, 1, 28, 28))\n",
    "        reconstruction, mu, logvar = vaes[digit_idx](x)\n",
    "        nll = loss_function(reconstruction, x, mu, logvar)\n",
    "        return nll\n",
    "    return visual_model\n",
    "visual_models = [create_visual_model(i, vaes) for i in xrange(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading digit 0\n",
      "Loading digit 1\n",
      "Loading digit 2\n",
      "Loading digit 3\n",
      "Loading digit 4\n",
      "Loading digit 5\n",
      "Loading digit 6\n",
      "Loading digit 7\n",
      "Loading digit 8\n",
      "Loading digit 9\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Load all MNISTs\n",
    "batch_size = 1\n",
    "\n",
    "# Load all MNIST digits\n",
    "test_digits = {}\n",
    "test_loaders = {}\n",
    "for i in xrange(10):\n",
    "    print 'Loading digit', i\n",
    "    test_digit = get_digit(i, train=False)\n",
    "    test_digits[i] = test_digit\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(test_digit, batch_size=batch_size, shuffle=True)\n",
    "    test_loaders[i] = test_loader\n",
    "    \n",
    "# Build visual samplers (from test set)\n",
    "def create_visual_sampler(i, test_loaders):\n",
    "    def visual_sampler():\n",
    "        return iter(test_loaders[int(i)]).next()[0][0,0]\n",
    "    return visual_sampler\n",
    "visual_samplers = [create_visual_sampler(i, test_loaders) for i in xrange(10)]\n",
    "\n",
    "print visual_samplers[8]().size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Symbolic Combination to Image Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size torch.Size([5, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combination to Visual\n",
    "def to_visual(combination, visual_samplers):\n",
    "    '''\n",
    "    Sample a visual representation for a symbolic combination\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    combination: np.ndarray (part~5) combination to encode\n",
    "    visual_samplers: dict of 10 callable objects which return a random corresponding (28, 28) digit\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    visual_combination: torch.Tensor (part~5, height~28, width~28)\n",
    "    '''\n",
    "    x = []\n",
    "    for c in combination:\n",
    "        sample = visual_samplers[c]()\n",
    "        x.append(sample[None, :, :])\n",
    "    visual_combination = torch.cat(x)\n",
    "    return visual_combination\n",
    "\n",
    "# Test: combination to visual_combination    \n",
    "visual_combination = to_visual([3, 1, 4, 1, 5], visual_samplers)\n",
    "\n",
    "print 'Size', visual_combination.size()\n",
    "for i in xrange(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(visual_combination[i].numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood of Sum-25 with Joint generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x113864550>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precompute conditional visual likelihoods\n",
    "def get_per_digit_likelihood(visual_combination, visual_models):  # return -log likelihoods\n",
    "    '''\n",
    "    Compute NLL given by each visual model (e.g. VAE) to each visual digit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    visual_combination: torch.Tensor (part~5, height~28, width~28)\n",
    "    visual_models: dictionary of objects which can be called on x and return a nll\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    visual_likelihoods: np.ndarray (part~5, digit~10)\n",
    "    '''\n",
    "    visual_likelihoods = np.zeros((5, 10))\n",
    "    for part in xrange(5):\n",
    "        for model_idx in xrange(10):\n",
    "            digit_image = visual_combination[part]\n",
    "            l = visual_models[model_idx](digit_image)\n",
    "            visual_likelihoods[part, model_idx] = l  # since it's -log likelihood\n",
    "    return visual_likelihoods\n",
    "\n",
    "# Test: get conditional nll for each digit of visual combination\n",
    "visual_likelihoods = get_per_digit_likelihood(visual_combination, visual_models)\n",
    "plt.imshow(visual_likelihoods, 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest combination match [3 1 4 8 9]\n",
      "Likelihood 481.3769402361114\n"
     ]
    }
   ],
   "source": [
    "# Sum over all combinations in symbolic model\n",
    "conditional_likelihoods = []\n",
    "\n",
    "def log_sum_exp(v):\n",
    "    v = np.asarray(v)\n",
    "    v_max = v.max()\n",
    "    return v_max + np.log(np.sum(np.exp(v - v_max)))\n",
    "\n",
    "\n",
    "def get_one_sample_likelihood(visual_likelihoods, model_combinations):\n",
    "    '''\n",
    "    Return likelihood given by a joint model for one visual sample.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    visual_likelihoods: np.ndarray (part~5, digit~10) of per_digit likelihoods\n",
    "    model_combinations: np.ndarray (combination~1000, part~5) \n",
    "        symbolic model is uniform distribution on those combinations.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    likelihood: nll for that given sample: -log { 1/|C| sum_{z\\in C} p(z) \\prod_i p(x_i | z_i) }\n",
    "    conditional_likelihoods: -\\sum_i \\log p(x_i | z_i)\n",
    "    closest_combination: return combination z in model_combinations with highest likelihood\n",
    "    '''\n",
    "    conditional_likelihoods = []\n",
    "    for combination in model_combinations:  # iterate over possible z\n",
    "        tmp = 0.\n",
    "        for part, c in enumerate(combination):\n",
    "            p_xPart_given_zPart = visual_likelihoods[part, c]\n",
    "            tmp += p_xPart_given_zPart\n",
    "        conditional_likelihoods.append(tmp)\n",
    "    likelihood = np.log(len(p.train_positive)) - log_sum_exp(-np.asarray(conditional_likelihoods))  # get NLL\n",
    "    # for debugging return closest combination\n",
    "    best_x_z = np.argmin(conditional_likelihoods)  # smallest log likelihood\n",
    "    closest_combination = p.train_positive[best_x_z]\n",
    "    return likelihood, conditional_likelihoods, closest_combination\n",
    "    \n",
    "    \n",
    "# Test: get liklelihood for sample giving visual_likelihood\n",
    "likelihood, conditional_likelihoods, closest_combination = get_one_sample_likelihood(\n",
    "    visual_likelihoods, p.train_positive)\n",
    "\n",
    "# Note that the largest conditional likelihood should correspond classifying the combination\n",
    "# if combination verifies constraint\n",
    "print 'Closest combination match', closest_combination\n",
    "print 'Likelihood', likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat this over all training set combinations X model combinations\n",
    "[Main Function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination # 0\n",
      "Combination [4 9 2 6 4]\n",
      "closest [4 9 2 6 4]\n",
      "Likelihood 515.6616694614848\n",
      "Average NLL: 515.7 +/- 0.0\n",
      "Combination # 50\n",
      "Combination [6 9 1 1 8]\n",
      "closest [6 9 1 1 8]\n",
      "Likelihood 386.8954646275007\n",
      "Average NLL: 497.0 +/- 8.2\n",
      "Combination # 100\n",
      "Combination [0 3 7 8 7]\n",
      "closest [0 3 7 8 7]\n",
      "Likelihood 468.18712875103586\n",
      "Average NLL: 496.2 +/- 5.7\n",
      "Combination # 150\n",
      "Combination [8 7 5 3 2]\n",
      "closest [8 7 5 3 2]\n",
      "Likelihood 515.4495265171491\n",
      "Average NLL: 490.6 +/- 4.7\n",
      "NLL in [483.1; 491.2]\n"
     ]
    }
   ],
   "source": [
    "def get_likelihood(target_combinations, model_combinations,\n",
    "                    visual_samplers, visual_models, max_iterations=200):\n",
    "    '''\n",
    "    Return estimated likelihood for \n",
    "    '''\n",
    "    all_likelihoods = []\n",
    "    for i, combination in enumerate(p.train_positive):  # true distribution to reach\n",
    "        \n",
    "        if i >= max_iterations:\n",
    "            break\n",
    "        \n",
    "        # Transform symbolic combination to visual\n",
    "        visual_combination = to_visual(combination, visual_samplers)\n",
    "        \n",
    "        # Compute likelihood of each part(digit) with each visual conditional model \n",
    "        visual_likelihoods = get_per_digit_likelihood(visual_combination, visual_models)  \n",
    "        \n",
    "        # Compute likelihood of that visual sample\n",
    "        likelihood, conditional_likelihoods, closest_combination = get_one_sample_likelihood(\n",
    "            visual_likelihoods, model_combinations)  # model distribution\n",
    "\n",
    "        # Logging\n",
    "        all_likelihoods.append(likelihood)\n",
    "        average_nll = np.mean(all_likelihoods)\n",
    "        std = np.std(all_likelihoods) / np.sqrt(len(all_likelihoods))\n",
    "        if i % 50 == 0:\n",
    "            print 'Combination #', i\n",
    "            print 'Combination', combination\n",
    "            print 'closest', closest_combination\n",
    "            print 'Likelihood', likelihood\n",
    "            print 'Average NLL: {:.1f} +/- {:.1f}'.format(average_nll, std) \n",
    "            \n",
    "    return average_nll, std\n",
    "\n",
    "target_combinations = p.train_positive\n",
    "model_combinations = p.train_positive\n",
    "average_nll, std = get_likelihood(target_combinations, model_combinations,\n",
    "                    visual_samplers, visual_models, max_iterations=200)\n",
    "\n",
    "print 'NLL in [{:.1f}; {:.1f}]'.format(average_nll-std, average_nll+std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
